{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "54lItyyM7DOx",
        "outputId": "fb049e3b-6b88-4ec6-91f5-b83bff0298bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.1.1)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=b6b3ab9df5d188fd2f7500fe23d7e3afef93a833eb6a5550cef99aed2747b7fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import requests\n",
        "import openai\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from typing import List, Tuple\n",
        "from io import BytesIO\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path(\"gdrive/MyDrive/data/\")\n"
      ],
      "metadata": {
        "id": "rKbEm92YAb4Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "dpTJhygg-EFm",
        "outputId": "24c976cc-ce14-4b6a-a63f-2d02dd7a6d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TuI6GSSs9iL9"
      },
      "outputs": [],
      "source": [
        "labels = pd.read_csv(\"labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vB78gZmI7DO0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def query_dalle(prompt, n=1):\n",
        "  return openai.Image.create(\n",
        "    prompt=prompt,\n",
        "    n=n,\n",
        "    size=\"256x256\"\n",
        "  )\n",
        "\n",
        "def read_json(path) -> dict:\n",
        "    with open(path) as f:\n",
        "        return json.load(f)\n",
        "      \n",
        "\n",
        "config = read_json(\"openai_config.json\")\n",
        "openai.api_key = config[\"key\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6JJGdi9F7DO1"
      },
      "outputs": [],
      "source": [
        "MONK = {\n",
        "    \"monk_1\": \"very pale\",\n",
        "    \"monk_2\": \"pale\",\n",
        "    \"monk_3\": \"light\",\n",
        "    \"monk_4\": \"olive\",\n",
        "    \"monk_5\": \"light brown\",\n",
        "    \"monk_6\": \"brown\",\n",
        "    \"monk_7\": \"dark brown\",\n",
        "    \"monk_8\": \"dark\",\n",
        "    \"monk_9\": \"black\",\n",
        "    \"monk_10\": \"very black\"\n",
        "}\n",
        "\n",
        "def create_prompt(age, gender, skin_tone) -> str: \n",
        "  age_min, age_max = age.split(\"_\")\n",
        "  new_age = random.randint(a=int(age_min), b=int(age_max))\n",
        "  monk = MONK[skin_tone] \n",
        "  base_prompt =  \"a face photo of a XXX year old, YYY-skinned ZZZ, photo-realistic\"\n",
        "  return base_prompt.replace(\"XXX\", str(new_age)).replace(\"YYY\", monk).replace(\"ZZZ\", gender)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L9OiDc62_zzy"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "combis = list(itertools.product(labels[\"age\"].dropna().unique(), [\"male\", \"female\"], MONK.keys()))\n",
        "prompts = {(age, gender, skin_tone): create_prompt(age=age, gender=gender, skin_tone=skin_tone) for age, gender, skin_tone in combis}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MBt_Yt_3SOP",
        "outputId": "6135d4ad-ea6d-4fe6-b9f4-3676a7776fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('18_30', 'male', 'monk_1'): [1], ('18_30', 'male', 'monk_2'): [], ('18_30', 'male', 'monk_3'): [], ('18_30', 'male', 'monk_4'): [], ('18_30', 'male', 'monk_5'): [], ('18_30', 'male', 'monk_6'): [], ('18_30', 'male', 'monk_7'): [], ('18_30', 'male', 'monk_8'): [], ('18_30', 'male', 'monk_9'): [], ('18_30', 'male', 'monk_10'): [], ('18_30', 'female', 'monk_1'): [], ('18_30', 'female', 'monk_2'): [], ('18_30', 'female', 'monk_3'): [], ('18_30', 'female', 'monk_4'): [], ('18_30', 'female', 'monk_5'): [], ('18_30', 'female', 'monk_6'): [], ('18_30', 'female', 'monk_7'): [], ('18_30', 'female', 'monk_8'): [], ('18_30', 'female', 'monk_9'): [], ('18_30', 'female', 'monk_10'): [], ('0_17', 'male', 'monk_1'): [], ('0_17', 'male', 'monk_2'): [], ('0_17', 'male', 'monk_3'): [], ('0_17', 'male', 'monk_4'): [], ('0_17', 'male', 'monk_5'): [], ('0_17', 'male', 'monk_6'): [], ('0_17', 'male', 'monk_7'): [], ('0_17', 'male', 'monk_8'): [], ('0_17', 'male', 'monk_9'): [], ('0_17', 'male', 'monk_10'): [], ('0_17', 'female', 'monk_1'): [], ('0_17', 'female', 'monk_2'): [], ('0_17', 'female', 'monk_3'): [], ('0_17', 'female', 'monk_4'): [], ('0_17', 'female', 'monk_5'): [], ('0_17', 'female', 'monk_6'): [], ('0_17', 'female', 'monk_7'): [], ('0_17', 'female', 'monk_8'): [], ('0_17', 'female', 'monk_9'): [], ('0_17', 'female', 'monk_10'): [], ('31_60', 'male', 'monk_1'): [], ('31_60', 'male', 'monk_2'): [], ('31_60', 'male', 'monk_3'): [], ('31_60', 'male', 'monk_4'): [], ('31_60', 'male', 'monk_5'): [], ('31_60', 'male', 'monk_6'): [], ('31_60', 'male', 'monk_7'): [], ('31_60', 'male', 'monk_8'): [], ('31_60', 'male', 'monk_9'): [], ('31_60', 'male', 'monk_10'): [], ('31_60', 'female', 'monk_1'): [], ('31_60', 'female', 'monk_2'): [], ('31_60', 'female', 'monk_3'): [], ('31_60', 'female', 'monk_4'): [], ('31_60', 'female', 'monk_5'): [], ('31_60', 'female', 'monk_6'): [], ('31_60', 'female', 'monk_7'): [], ('31_60', 'female', 'monk_8'): [], ('31_60', 'female', 'monk_9'): [], ('31_60', 'female', 'monk_10'): [], ('61_100', 'male', 'monk_1'): [], ('61_100', 'male', 'monk_2'): [], ('61_100', 'male', 'monk_3'): [], ('61_100', 'male', 'monk_4'): [], ('61_100', 'male', 'monk_5'): [], ('61_100', 'male', 'monk_6'): [], ('61_100', 'male', 'monk_7'): [], ('61_100', 'male', 'monk_8'): [], ('61_100', 'male', 'monk_9'): [], ('61_100', 'male', 'monk_10'): [], ('61_100', 'female', 'monk_1'): [], ('61_100', 'female', 'monk_2'): [], ('61_100', 'female', 'monk_3'): [], ('61_100', 'female', 'monk_4'): [], ('61_100', 'female', 'monk_5'): [], ('61_100', 'female', 'monk_6'): [], ('61_100', 'female', 'monk_7'): [], ('61_100', 'female', 'monk_8'): [], ('61_100', 'female', 'monk_9'): [], ('61_100', 'female', 'monk_10'): []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm7FOmJjA2Jh",
        "outputId": "07332cd1-6712-4021-e82f-575873d49298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [14:15<00:00, 10.70s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "responses = {cats: [] for cats in prompts}\n",
        "for cats, prompt in tqdm(prompts.items()):\n",
        "  try:\n",
        "    response = query_dalle(prompt)\n",
        "    responses[cats].append(response[\"data\"])\n",
        "  except openai.APIError:\n",
        "    print(\"caught an error!\")\n",
        "    time.sleep(10)\n",
        "    try:\n",
        "      response = query_dalle(prompt)\n",
        "      responses[cats].append(response[\"data\"])\n",
        "    except openai.APIError as e:\n",
        "      print(\"another one\")\n",
        "      raise e \n",
        "  time.sleep(5)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tyn9kQ0zFm94"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TsVqWVV-ETMz"
      },
      "outputs": [],
      "source": [
        "def read_img(path, img_size: Tuple[int, int]=(224,224)) -> Image.Image:\n",
        "    return Image.open(path).convert(\"RGB\").resize(img_size)\n",
        "\n",
        "def read_img_url(url: str) -> Image.Image:\n",
        "    response = requests.get(url)\n",
        "    return read_img(BytesIO(response.content))\n",
        "\n",
        "imgs = {cat: read_img_url(respons[0][0][\"url\"]) for cat, respons in responses.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = np.array([np.array(img) for img in imgs.values()])\n",
        "img_array.shape\n"
      ],
      "metadata": {
        "id": "gGgLEcjE8qc7",
        "outputId": "30650326-ca54-489b-b8a4-e9e2c528a138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "with open(DATA_DIR / \"dalle_img_dict.pkl\", \"wb\") as f:\n",
        "  pickle.dump(imgs, f)"
      ],
      "metadata": {
        "id": "U7dbvzV1-SnM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vgg16():\n",
        "    # download VGG-16 with fully connected layers\n",
        "    vgg = tf.keras.applications.vgg16.VGG16(\n",
        "        include_top=True,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(224, 224, 3),\n",
        "        pooling=None,\n",
        "        classes=1000,\n",
        "        classifier_activation=\"softmax\",\n",
        "    )\n",
        "    # remove the classification layer\n",
        "    new_model = tf.keras.models.Sequential()\n",
        "    for layer in vgg.layers[:-1]:\n",
        "        new_model.add(layer)\n",
        "    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "    x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
        "    outputs = new_model(x)\n",
        "    final_vgg = tf.keras.Model(inputs, outputs)\n",
        "    return final_vgg"
      ],
      "metadata": {
        "id": "RYS3_xyE-wdr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = create_vgg16()"
      ],
      "metadata": {
        "id": "dpoUJPzz_sVY",
        "outputId": "64375b40-4d7f-4163-954d-72cc235bfb61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 24s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pickle(path: Path): \n",
        "  with open(path, \"rb\") as f:\n",
        "    return pickle.load(f)\n",
        "\n",
        "img_dict = read_pickle(DATA_DIR / \"dalle_img_dict.pkl\")"
      ],
      "metadata": {
        "id": "AEbz32Jy_wf4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_arr = np.array([np.array(img) for img in img_dict.values()])"
      ],
      "metadata": {
        "id": "kNAPPi-cAlLQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5LdkiRcOhKo",
        "outputId": "f9c92195-0f7b-4b99-f716-8b890eb4e64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 173ms/step\n"
          ]
        }
      ],
      "source": [
        "dalle_preds = vgg16.predict(img_arr)\n",
        "assert dalle_preds.shape[0] == 80"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import KDTree\n",
        "from collections import Counter\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "def most_common(arr) -> int:\n",
        "  counts = np.bincount(arr.astype(int))\n",
        "  return np.argmax(counts)\n",
        "\n",
        "\n",
        "def map_to_int(x: List[str]) -> Tuple[np.array, Dict[int, str]]:\n",
        "    \"\"\"Map a list of strings to a list of ints and a dict mapping ints to strings.\"\"\"\n",
        "    mapping = {s: i for i, s in enumerate(set(x))}\n",
        "    return np.array([mapping[s] for s in x]), mapping\n",
        "\n",
        "def invert_dict(d: dict) -> dict:\n",
        "  return {v: k for k, v in d.items()}\n",
        "\n",
        "class DalleKNN:\n",
        "  def __init__(self, labels: List[Tuple[str, str, str]]):\n",
        "    self.labels = labels\n",
        "    self.ages, self.age_map = map_to_int([x[0] for x in self.labels])\n",
        "    self.genders, self.gender_map =  map_to_int([x[1] for x in self.labels])\n",
        "    self.skin_tones, self.skin_tone_map =  map_to_int([x[2] for x in self.labels])\n",
        "    assert len(np.unique(self.skin_tones)) == 10, \"mismatch!\"\n",
        "    self.age_map = invert_dict(self.age_map)\n",
        "    self.gender_map = invert_dict(self.gender_map)\n",
        "    self.skin_tone_map = invert_dict(self.skin_tone_map)\n",
        "    \n",
        "  def fit(self, dalle_preds: np.ndarray):\n",
        "    self.kdtree = KDTree(dalle_preds)\n",
        "  \n",
        "  def find_match(self, new_img, k=3) -> Tuple[str, str, str]:\n",
        "    dist, idx = self.kdtree.query(new_img, k=k)\n",
        "    age_pred = most_common(self.ages[idx])\n",
        "    gender_pred = most_common(self.genders[idx])\n",
        "    skin_tone_pred = most_common(self.skin_tones[idx])\n",
        "    return self.age_map[age_pred], self.gender_map[gender_pred], self.skin_tone_map[skin_tone_pred]\n",
        "  \n"
      ],
      "metadata": {
        "id": "4qth1j8jBIaN"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common(map_to_int([x[0] for x in cat_list]))"
      ],
      "metadata": {
        "id": "Hnht-uwLHERX",
        "outputId": "106024bd-72ad-4bfe-8467-0670cc975d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = np.load(DATA_DIR / \"vgg_test_preds.npy\")"
      ],
      "metadata": {
        "id": "Qkeq1M8lDF1H"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_list = [cat for cat in img_dict]\n",
        "\n",
        "test_knn = DalleKNN(cat_list)\n",
        "test_knn.fit(dalle_preds)\n",
        "test_knn.find_match(dalle_preds[0])"
      ],
      "metadata": {
        "id": "SgpFwVTzC6rb",
        "outputId": "3ea22a07-ef1d-4793-ec3f-af2152da56d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0_17', 'male', 'monk_1')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = pd.read_csv(DATA_DIR / \"test_labels.csv\", index_col=0)\n",
        "test_imgs = np.load(DATA_DIR / \"vgg_test_preds.npy\")\n"
      ],
      "metadata": {
        "id": "s_Ssb1BZDe-j"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_preds = []\n",
        "gender_preds = []\n",
        "skin_preds = []\n",
        "\n",
        "for (i, row), test_img in zip(test_labels.iterrows(), test_imgs):\n",
        "  agepred, genderpred, skinpred = test_knn.find_match(test_img)\n",
        "  age_preds.append(agepred)  \n",
        "  gender_preds.append(genderpred)  \n",
        "  skin_preds.append(skinpred)  \n"
      ],
      "metadata": {
        "id": "MT8sBu0RM-oC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "CgUpRxb9OdkR"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getScore(results):\n",
        "    acc = results['accuracy']\n",
        "    disp = results['disparity']\n",
        "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
        "    return ad\n",
        "\n",
        "  results "
      ],
      "metadata": {
        "id": "B-b9nSydPnzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGlAlgqF7vdM"
      },
      "outputs": [],
      "source": [
        "#np.save(\"gdrive/MyDrive/data/dalle_imgs_preprocessed.npy\", processed_imgs)\n",
        "processed_imgs = np.load(\"gdrive/MyDrive/data/dalle_imgs_preprocessed.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjQgXc79QJxU",
        "outputId": "29e1c173-906b-49a2-e0e7-8d5ebbceb4a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 12s 841ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = new_model.predict(processed_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp2mJ4ZmQPfm",
        "outputId": "31f1deab-5ccd-4ed4-9f4c-cf0dd46083ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(79, 4096)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUZ16q0_PJ5N"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"gdrive/MyDrive/data/dalle_imgs.pkl\", \"wb\") as f:\n",
        "  pickle.dump(imgs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzPS7hAlQpC6"
      },
      "outputs": [],
      "source": [
        "# Now lets try to load all the (test) imgs\n",
        "!unzip -q gdrive/MyDrive/data_bb1_img_recognition.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcK_txA2Q9De"
      },
      "outputs": [],
      "source": [
        "test_labels = pd.read_csv(next(Path(\"test\").glob(\"*.csv\")))\n",
        "test_imgs = [tf.keras.utils.load_img(Path(\"test\") / path, target_size=(224, 224)) for path in test_labels[\"name\"]]\n",
        "test_preprocessed = [preprocess(np.asarray(img)) for img in test_imgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUnFt-XXR2y3",
        "outputId": "7f65bd02-a516-4140-f0cc-54f7989f3c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 15s 166ms/step\n"
          ]
        }
      ],
      "source": [
        "test_preds = new_model.predict(np.array(test_preprocessed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fg0clXXSvp0"
      },
      "outputs": [],
      "source": [
        "np.save(\"gdrive/MyDrive/data/vgg_test_preds.npy\", test_preds)\n",
        "np.save(\"gdrive/MyDrive/data/vgg_dalle_preds.npy\", preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpewfRNVTELL"
      },
      "source": [
        "# Pedal to the metal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTugd889wggo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def read_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "dalle_preds = np.load(\"../train/vgg_dalle_preds.npy\")\n",
        "test_preds = np.load(\"../train/vgg_test_preds.npy\")\n",
        "test_labels = pd.read_csv(\"../test/labels.csv\", index_col=0)\n",
        "dalle_imgs = read_pickle(\"../train/dalle_imgs.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMVs-dvLwggp"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import KDTree\n",
        "\n",
        "tree = KDTree(dalle_preds)\n",
        "dist, ind = tree.query(test_preds, k=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "nvRz3w2iwggq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipbUaMobwggr",
        "outputId": "f9939314-35b8-4fe2-9b85-25c4246970b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>skin_tone</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>real_face</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>TEST1475.png</td>\n",
              "      <td>monk_10</td>\n",
              "      <td>male</td>\n",
              "      <td>0_17</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              name skin_tone gender   age  real_face\n",
              "1475  TEST1475.png   monk_10   male  0_17        1.0"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "black_test = test_labels[test_labels[\"skin_tone\"] == \"monk_10\"].sample(1)\n",
        "black_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbgNQZgHwggr"
      },
      "outputs": [],
      "source": [
        "test_"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('waldo')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3728cfcf275f18009e83b3c060135d2ac0dcb2409e2f4caa1bbd460837734472"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
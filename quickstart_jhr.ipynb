{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd235fb0",
   "metadata": {},
   "source": [
    "# Bias Buccaneers Image Recognition Challenge: Quickstart\n",
    "\n",
    "This notebook will introduce you to the data and describe a workflow to train and evaluate a baseline model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57b0b7",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "We start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2454f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "logger = logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f1fd6",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Make sure to download and uncompress the data (`data_bb1_img_recognition.zip`) in the folder you're working off of.\n",
    "\n",
    "We first load the file containing the labels, binarize labels of each of the three classes as a numpy array and store them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7545622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def load_rgb(path: Path, rgb=False) -> np.ndarray:\n",
    "    img = cv2.imread(str(path))\n",
    "    if not rgb:\n",
    "        return img\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_img(img):\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def resize_img(img, width: int=64, height: int=64):\n",
    "    return cv2.resize(img, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c742f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "LOADPATH = Path(\"../Downloads/data_bb1/train/\")\n",
    "assert LOADPATH.exists()\n",
    "SAVEPATH = './models/'\n",
    "df = pd.read_csv( \"train/labels.csv\")\n",
    "aug_df = pd.read_csv(LOADPATH / \"intersect_augment.csv\")\n",
    "new_aug = aug_df[[\"aug_name\", \"skin_tone\", \"gender\", \"age\"]].rename({\"aug_name\": \"name\"}, axis=1)\n",
    "df_labeled = pd.concat([df.loc[df[\"real_face\"] == 1, [\"name\", \"skin_tone\", \"gender\", \"age\"]], new_aug], axis=0).dropna().reset_index(drop=True)\n",
    "age_counts = df_labeled[\"age\"].value_counts()\n",
    "# downsample to min class\n",
    "min_class = age_counts.min()\n",
    "df_labeled = df_labeled.groupby(\"age\").apply(lambda x: x.sample(min_class)).reset_index(drop=True)\n",
    "\n",
    "# Converting labels to np array\n",
    "cat = ['skin_tone','gender','age']\n",
    "lbs = [LabelBinarizer() for i in range(3)]\n",
    "Y = []\n",
    "for i in range(3):\n",
    "    lab = lbs[i].fit_transform(df_labeled[cat[i]])\n",
    "    if lab.shape[1]==1:\n",
    "        Y.append(np.hstack((1-lab,lab)))\n",
    "    else:\n",
    "        Y.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb007f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"real_face\"] == 1].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b828fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def great_load(path):\n",
    "    return resize_img(load_rgb(path, rgb=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2dfcbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n",
      "Converting images to np array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loading and converting data into np array\n",
    "print(\"Loading images\")\n",
    "length = width = 64 # size for each input image, increase if you want\n",
    "nn = df_labeled.shape[0]\n",
    "all_imgs = [great_load(LOADPATH / df_labeled['name'][i]) for i in range(nn)]\n",
    "#all_imgs = [image.load_img(LOADPATH/df_labeled.iloc[i]['name'], target_size=(length,width)) for i in range(nn)]\n",
    "\n",
    "print(\"Converting images to np array\")\n",
    "X = np.empty([nn, length, width, 3], dtype=float)\n",
    "for i in range(nn):\n",
    "    X[i,:] = image.img_to_array(all_imgs[i])\n",
    "X = K.applications.resnet50.preprocess_input(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb73277",
   "metadata": {},
   "source": [
    "We then load the images under the training set and convert them to numpy arrays. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f957a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1000)\n",
    "def load_rgb(path: Path, rgb=False) -> np.ndarray:\n",
    "    img = cv2.imread(str(path))\n",
    "    if not rgb:\n",
    "        return img\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_img(img):\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "testimg = load_rgb(LOADPATH / df_labeled.loc[1, \"name\"])\n",
    "\n",
    "show_img(testimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf14ba8",
   "metadata": {},
   "source": [
    "## Specify the Model\n",
    "\n",
    "We define a single model class that is able train on the data in `X` and `Y` and predict outcomes for all three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c55abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel():\n",
    "    def __init__(self, X, Y, idx):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.idx = idx\n",
    "        self.trainX, self.testX = X[idx[0],:], X[idx[1],:]\n",
    "        self.trainY, self.testY = [Y[i][idx[0],:] for i in range(3)], [Y[i][idx[1],:] for i in range(3)]\n",
    "        self.cat = ['skin_tone','gender','age']\n",
    "        self.loss = ['categorical_crossentropy' for i in range(3)]\n",
    "        self.metrics = [['accuracy'] for i in range(3)]\n",
    "        self.models = [None]*3\n",
    "\n",
    "    # train a model specific for a certain class index in self.cat\n",
    "    def fit(self, index, model, epochs=5, batch_size=32, save=False, save_location=None, verbose=1):\n",
    "        \n",
    "        if verbose: print(\"Training model for \"+self.cat[index])\n",
    "        model.add(K.layers.Dense(self.trainY[index].shape[1], activation='softmax'))\n",
    "        model.compile(loss=self.loss[index], optimizer='Adam', metrics=self.metrics[index])\n",
    "        model.fit(\n",
    "            self.trainX, self.trainY[index], \n",
    "            validation_data=(self.testX,self.testY[index]), \n",
    "            batch_size=batch_size, epochs=epochs, verbose=verbose\n",
    "        )\n",
    "        if save:\n",
    "            if os.path.exists(SAVEPATH)==False:\n",
    "                print('save location '+SAVEPATH+' did not exist. creating')\n",
    "                os.makedirs(SAVEPATH)\n",
    "            SAVE_LOCATION = save_location+'model_'+cat[index]+'.h5'\n",
    "            print(\"saving model at \"+SAVE_LOCATION)\n",
    "            model.save(SAVE_LOCATION)\n",
    "        self.models[index] = model\n",
    "            \n",
    "    def predict(self, newX):\n",
    "        predictions = [model.predict(newX) for model in self.models]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ae9ef",
   "metadata": {},
   "source": [
    "## Initialize and Train a Model\n",
    "\n",
    "We now train a `PredictionModel` to predict the likely skin tone, gender, and age of an input image. This baseline model is initialize on imagenet weights and uses the ResNet50 architecture. We strongly recommend using a GPU to reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da29fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for age\n",
      "Epoch 1/5\n",
      " 15/238 [>.............................] - ETA: 3:47 - loss: 1.7815 - accuracy: 0.2833"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jhr\\face_recognition_bounty\\quickstart_jhr.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m mymodel \u001b[39m=\u001b[39m PredictionModel(X\u001b[39m=\u001b[39mX, Y\u001b[39m=\u001b[39mY, idx\u001b[39m=\u001b[39m[train_idx,test_idx])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m mymodel\u001b[39m.\u001b[39;49mfit(index\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, model\u001b[39m=\u001b[39;49minitializeModel(), epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_location\u001b[39m=\u001b[39;49mSAVEPATH)\n",
      "\u001b[1;32mc:\\Users\\jhr\\face_recognition_bounty\\quickstart_jhr.ipynb Cell 15\u001b[0m in \u001b[0;36mPredictionModel.fit\u001b[1;34m(self, index, model, epochs, batch_size, save, save_location, verbose)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39madd(K\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainY[index]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss[index], optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics[index])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainX, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainY[index], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtestX,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtestY[index]), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m save:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jhr/face_recognition_bounty/quickstart_jhr.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(SAVEPATH)\u001b[39m==\u001b[39m\u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jhr\\Anaconda3\\envs\\cds-vis\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# function to initialize a model\n",
    "def initializeModel():\n",
    "    res_model = ResNet50(include_top=False, weights='imagenet', input_tensor=K.Input(shape=[length,width,3]))\n",
    "\n",
    "    # freeze all but the last layer\n",
    "    for layer in res_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "    model = K.models.Sequential()\n",
    "    model.add(res_model)\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(256, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(128, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(64, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    return model\n",
    "\n",
    "nntrain = int(0.7*nn)\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(nn)\n",
    "train_idx, test_idx = indices[:nntrain], indices[nntrain:]\n",
    "mymodel = PredictionModel(X=X, Y=Y, idx=[train_idx,test_idx])\n",
    "\n",
    "# train model\n",
    "mymodel.fit(index=2, model=initializeModel(), epochs=5, save=True, save_location=SAVEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527b5ae",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "We now evaluate the model on the test data. To do this, let's first load up that data and structure it similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ab27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test labels to np array\n",
      "Loading test images\n",
      "Converting test images to np array\n"
     ]
    }
   ],
   "source": [
    "# load labels data\n",
    "TESTPATH = LOADPATH.parent / 'test'\n",
    "df_test = pd.read_csv(TESTPATH /'labels.csv')\n",
    "\n",
    "# Convert labels to np array\n",
    "print(\"Converting test labels to np array\")\n",
    "testY = []\n",
    "for i in range(3):\n",
    "    lab = lbs[i].fit_transform(df_test[cat[i]])\n",
    "    if lab.shape[1]==1:\n",
    "        testY.append(np.hstack((1-lab,lab)))\n",
    "    else:\n",
    "        testY.append(lab)\n",
    "        \n",
    "# load and convert images into np array\n",
    "print(\"Loading test images\")\n",
    "nt = df_test.shape[0]\n",
    "all_imgs = [great_load(TESTPATH / df_test.iloc[i]['name']) for i in range(nt)]\n",
    "\n",
    "print(\"Converting test images to np array\")\n",
    "testX = np.empty([nt, length, width, 3], dtype=float)\n",
    "for i in range(nt):\n",
    "    testX[i,:] = image.img_to_array(all_imgs[i])\n",
    "testX = K.applications.resnet50.preprocess_input(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ee94e",
   "metadata": {},
   "source": [
    "We then obtain predicted labels for skin tone, gender, and age as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf106302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mymodel.models[2].predict(testX)\n",
    "predY = pred.argmax(axis=1)\n",
    "predLabels = [lbs[2].classes_[j] for j in predY]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cf73d",
   "metadata": {},
   "source": [
    "Finally, we calculate the label-wise accuracy and disparity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081d5cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_acc=[0.5565749235474006, 0.5993079584775086, 0.397172236503856, 0.22764227642276422]\n",
      "min(all_acc)=0.22764227642276422\n",
      "max(all_acc)=0.5993079584775086\n",
      "{'accuracy': {'age': 0.5223333333333333}, 'disparity': {'age': 0.3716656820547444}}\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "acc = {}\n",
    "icat = cat[2]\n",
    "iacc = accuracy_score(df_test[cat[2]], predLabels)\n",
    "acc[icat] = iacc\n",
    "\n",
    "# calculate disparity\n",
    "def disparity_score(ytrue, ypred):\n",
    "    cm = confusion_matrix(ytrue,ypred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    all_acc = list(cm.diagonal())\n",
    "    print(f\"{all_acc=}\\n{min(all_acc)=}\\n{max(all_acc)=}\")\n",
    "    return max(all_acc) - min(all_acc)\n",
    "\n",
    "disp = {}\n",
    "icat = cat[2]\n",
    "idisp = disparity_score(df_test[cat[2]], predLabels)\n",
    "disp[icat] = idisp\n",
    "disp\n",
    "\n",
    "results = {'accuracy': acc, 'disparity': disp}\n",
    "print(results)\n",
    "\n",
    "# save results\n",
    "with open(SAVEPATH+'results.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9bec872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[364, 220,  61,   9],\n",
       "       [207, 866, 344,  28],\n",
       "       [109, 342, 309,  18],\n",
       "       [ 19,  27,  49,  28]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test[cat[2]], predLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b0fcd",
   "metadata": {},
   "source": [
    "# Score Model and Prepare Submission\n",
    "\n",
    "Based on the above metric, we now calculate the score to evaluate your submission. This score will be displayed in your public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32712a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age score: 1.8007, max: 4\n"
     ]
    }
   ],
   "source": [
    "age_score = results[\"accuracy\"][\"age\"] * 4 * (1 - results[\"disparity\"][\"age\"]**2)\n",
    "print(f\"Age score: {age_score:.4f}, max: 4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db5b9086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'submission_name': '8-Bit Bias Bounty Baseline',\n",
       " 'score': 4.705572543130653,\n",
       " 'metrics': {'accuracy': {'skin_tone': 0.25766666666666665,\n",
       "   'gender': 0.7966666666666666,\n",
       "   'age': 0.5783333333333334},\n",
       "  'disparity': {'skin_tone': 0.5514223194748359,\n",
       "   'gender': 0.1493182689960596,\n",
       "   'age': 0.7802908824936}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getScore(results):\n",
    "    acc = results['accuracy']\n",
    "    disp = results['disparity']\n",
    "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
    "    return ad\n",
    "\n",
    "title = '8-Bit Bias Bounty Baseline'\n",
    "    \n",
    "submission = {\n",
    "    'submission_name': title,\n",
    "    'score': getScore(results),\n",
    "    'metrics': results\n",
    "}\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19070a4e",
   "metadata": {},
   "source": [
    "Finally, let's export this as a json file to upload as part of filling out your [submission form](https://docs.google.com/forms/d/e/1FAIpQLSfwqtVkJBVRP6TnFp7vHbbH8SlwKZJFIjvGQy7TyYFc8HR1hw/viewform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c30e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"baseline_score.json\", \"w\") as f:\n",
    "    json.dump(submission, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('cds-vis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "83db3168067e97115b16528dd771939296c5a9869e87b43a6cc607e3277c1e98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from typing import Dict, Tuple, List\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def create_vgg16():\n",
    "    # download VGG-16 with fully connected layers\n",
    "    vgg = tf.keras.applications.vgg16.VGG16(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "    # remove the classification layer\n",
    "    new_model = tf.keras.models.Sequential()\n",
    "    for layer in vgg.layers[:-1]:\n",
    "        new_model.add(layer)\n",
    "    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
    "    outputs = new_model(x)\n",
    "    final_vgg = tf.keras.Model(inputs, outputs)\n",
    "    return final_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model logic\n",
    "\n",
    "def most_common(arr) -> int:\n",
    "  counts = np.bincount(arr.astype(int))\n",
    "  return np.argmax(counts)\n",
    "\n",
    "\n",
    "def map_to_int(x: List[str]) -> Tuple[np.array, Dict[int, str]]:\n",
    "    \"\"\"Map a list of strings to a list of ints and a dict mapping ints to strings.\"\"\"\n",
    "    mapping = {s: i for i, s in enumerate(set(x))}\n",
    "    return np.array([mapping[s] for s in x]), mapping\n",
    "\n",
    "def invert_dict(d: dict) -> dict:\n",
    "  return {v: k for k, v in d.items()}\n",
    "\n",
    "class DalleKNN:\n",
    "  def __init__(self, labels: List[Tuple[str, str, str]]):\n",
    "    self.labels = labels\n",
    "    self.ages, self.age_map = map_to_int([x[0] for x in self.labels])\n",
    "    self.genders, self.gender_map =  map_to_int([x[1] for x in self.labels])\n",
    "    self.skin_tones, self.skin_tone_map =  map_to_int([x[2] for x in self.labels])\n",
    "    assert len(np.unique(self.skin_tones)) == 10, \"mismatch!\"\n",
    "    self.age_map = invert_dict(self.age_map)\n",
    "    self.gender_map = invert_dict(self.gender_map)\n",
    "    self.skin_tone_map = invert_dict(self.skin_tone_map)\n",
    "    \n",
    "  def fit(self, dalle_preds: np.ndarray):\n",
    "    self.kdtree = KDTree(dalle_preds)\n",
    "  \n",
    "  def find_match(self, new_img, k=3) -> Tuple[str, str, str]:\n",
    "    dist, idx = self.kdtree.query(new_img, k=k)\n",
    "    age_pred = most_common(self.ages[idx])\n",
    "    gender_pred = most_common(self.genders[idx])\n",
    "    skin_tone_pred = most_common(self.skin_tones[idx])\n",
    "    return self.age_map[age_pred], self.gender_map[gender_pred], self.skin_tone_map[skin_tone_pred]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "MODEL = read_pickle('models/oii_unsupervised.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model\n",
    "The model finds the nearest neighbour of a single image. The image have to be preprocessed by going through a VGG16 with the pretrained weights from imagenet. This can be initialized using the `create_vgg16()` function. This assumes images as np arrays of the shape (224, 224, 3). The below code illustrates loading the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = Path(\"test\") # path to the images (change for your own images)\n",
    "img_paths = IMG_DIR.glob(\"*.png\")\n",
    "\n",
    "# loading images\n",
    "imgs = [Image.open(img_path).resize((224, 224)) for img_path in img_paths]\n",
    "image_array = np.array([np.array(img) for img in imgs])\n",
    "\n",
    "# loading the VGG-16 model\n",
    "vgg = create_vgg16()\n",
    "featurized_images = vgg.predict(image_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict using our unsupervised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {\"age\": [], \"gender\": [], \"skin_tone\": []}\n",
    "\n",
    "for test_img in featurized_images:\n",
    "  agepred, genderpred, skinpred = MODEL.find_match(test_img)\n",
    "  preds[\"age\"].append(agepred)  \n",
    "  preds[\"gender\"].append(genderpred)  \n",
    "  preds[\"skin_tone\"].append(skinpred)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def disparity_score(ytrue, ypred):\n",
    "    cm = confusion_matrix(ytrue,ypred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    all_acc = list(cm.diagonal())\n",
    "    return max(all_acc) - min(all_acc)\n",
    "\n",
    "def evaluate_dict(test_df, pred_dict, score_func): \n",
    "  return {category: score_func(test_df[category], prediction) for category, prediction in pred_dict.items()}\n",
    "\n",
    "test_labels = pd.read_csv(\"test/labels.csv\") # path to the test labels\n",
    "\n",
    "results = {}\n",
    "results[\"accuracy\"] = evaluate_dict(test_labels, pred_dict=preds, score_func=accuracy_score)\n",
    "results[\"disparity\"] = evaluate_dict(test_labels, pred_dict=preds, score_func=disparity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(results):\n",
    "    acc = results['accuracy']\n",
    "    disp = results['disparity']\n",
    "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
    "    return ad\n",
    "\n",
    "title = \"OII Gang Unsupervised\"\n",
    "\n",
    "submission = {\n",
    "    'submission_name': title,\n",
    "    'score': getScore(results),\n",
    "    'metrics': results\n",
    "}\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('waldo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3728cfcf275f18009e83b3c060135d2ac0dcb2409e2f4caa1bbd460837734472"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
